---
title: "R Notebook"
output: github_document
---


This notebook plays a bit with web scraping. 

```{r}
#install.packages("rvest")
library(rvest)
```


```{r}
packt_page <- read_html("https://www.packtpub.com")
packt_page
```

If we want to scrape the papge title, we inspect the output of packt_page and we see there is only one title per page, wrapped withing <title> and <\title> tages.


```{r}
html_node(packt_page, "title")
```

To convert this into plain text, we run the function below:
```{r}
html_node(packt_page, "title") %>% html_text()
```

Another example: Scrap a list of all R-packages on CRAN

```{r}
cran_ml <- read_html("http://cran.r-project.org/web/views/MachineLearning.html")
cran_ml
```

Because we expect more than one result, we use "nodes" instead of "node"

```{r}
ml_packages <- html_nodes(cran_ml, "a")
head(ml_packages, n = 7)
```


## Parsing XML documents
XML is a plain text, human-readable, structured markup language upon which many document formats have been based. It employs a tagging structure in some ways similar to HTML, but is far stricter about formatting. For this reason, it is a popular online format to store structured datasets. 

Recently, the xm12 package has surfaced as an easier and more R-like interface to the libxm12 library. see package github for more details and examples. 