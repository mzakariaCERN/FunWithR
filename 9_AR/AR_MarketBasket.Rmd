---
title: "AR_MarketBastet"
author: "Mohammed Zakaria"
output: github_document
---

Our market basket analysis will utilize the purchase data from one month of operation for a grocery store. We will see that we have about 9835 transaction during that period. or about 30-50 per hour (depending on how many hours it operates). This indicates a medium size store. 


Getting the data

```{r}
#install.packages("arules")
library(arules)
# To see vignettes
#arules::arules
data("Groceries")
summary(Groceries)
inspect(Groceries[1:10])
as(Groceries[1:10], "list")
```


Number of rows means how many transactions we have. Number of columns means how many different items we might have in each transaction. The density of 0.02609146 indicates the ratio of nonzero matrix cells to total number of elements in the matrix ( which is equal to columns* rows = 1662115).
Total number of items purchased = 1662115* density = 43367
Average transaction contains 43367 / 9835 = 4.41 (which is the same value that summary gives us)

using inspect to see fea transaction records

```{r}
inspect(Groceries[1:5])
```

if we want to see the specific columns of the data, you can use [raw, column] notation. We can combine this with itemFrequency() to see the proportions of the transactions that contain the item

```{r}
inspect(Groceries[1:5, 1:3])
```

```{r}
itemFrequency(Groceries[, 1:4])
```

Notice that the sparce matrix columns are sorted in alphabetical order.


To present these statistics visually, we use itemFrequencyPlot() function. Since the transaction data requires a large number of items, we will need to limit the ones appearing in the plot in order to produce a readable chart.

```{r}
itemFrequencyPlot(Groceries, support = 0.1) # showing data with 10% support at least


```

Alternatively, we can set the limit on the number of items we wish to see, ranked by frequency

```{r}
itemFrequencyPlot(Groceries, topN = 20)
```

WE can alse view the entire sparce matrix using functiion image

```{r}
image(Groceries[1:5])
```

Notice that we have 5 rosw (number of transactions we want to look at, and 169 columns, indicating each item in the shopping transactions) This plot can help us with some quality control
1- (Ex. if we found one item that repeats all the way, it can be a sign that the store might include it's name on the records by mistake)
2- Viewing data historically can show seasonal effects

Rather than showing a large data set, we can simply sample few events 
```{r}
image(sample(Groceries, 100))
```


We will use the apriori algorithm in the arules package. WE might need to experiment few time with support and confidence levels to produce a reasonable number of association rules. Setting the level too high we will find no rules, or they would be too generic to be useful. If set too low, we will get a large nunmber of rulse, or worse, taking too much time to finish the learning task. Starting with the defauls settings (support = 0.1, confidence = 0.8). Since support level of 10% require the item to be visible at least 9385 * 0.1 = 939 times, and that we have only 8 items such, we shouldn't expect many rules (if any)

```{r}
apriori(Groceries)
```

One way to approach the problem of setting a threshold for support is to think about that smallest number of transactions you need before you would consider a pattern interesting. Perhaps an item that was purchased, say, 10 times a day would make it of interest. so we have 30*10 = 300. and out of 9000 transaction we have level of 3%. 

similar challenges go with setting confidence thresholds. We can try level 0.25, which means that the rule needs to be correct 25% of the time at least. Another variable to set is minlen. Setting it to 2 means we will eliminate rules that contain fewer than 2 items (rule count includes left hand and right hand items). 

```{r}
groceryrules <- apriori(Groceries, parameter = list(support = .006, confidence = 0.25, minlen = 2))
groceryrules
```
We see we have 463 rulse. 

```{r}
summary(groceryrules)
```
The min for support and confidence as the values we set. notice that there are varuations of support and confidence and that they are not all set around the threshold (in that case, it might indicate that it is too high). The third item is lift, which indicates how probable we have a causality due to the rule rather than random chance. A lrage lift value (more than 1, 2 etc) indicates that a rule is important, and reflects a strong connection between items. 

To inspect the rules, we use the inspect function

```{r}
inspect(groceryrules[1:4])
```


Let us take an example to understand these rules. the second rule means that if you buy pasta, you will buy whole milk. pasta and milk were bought 0.6 of the time in our data. and out of the occurances, 40% pasta was associated with whole milk. So the lift is 0.4 / 0.006 = 1.59

In general rules can be classified into 3 categories:  
Actionable  
Trivial (something we could have guessed without an algorithm Ex: formula and diapers)  
Inexplicable (we can't find an explanation or connection between the items that taking action might be impossible, it can be a random connection)  

We need to look for Actionable rules. 

Next we sort the rules by the lift

```{r}
inspect(sort(groceryrules, by = "lift")[1:5])
```

Taking subsets of the association rules

```{r}
berryrules <- subset(groceryrules, items %in% "berries")
inspect(berryrules)
```

We can save the results in csv
```{r}
#write(groceryrules, file = "groceryrules.csv", sep  = ",", quote = TRUE, row.names = FALSE)
```

We can also convert the rules to a data frame

```{r}
groceryrules_df <- as(groceryrules, "data.frame")
str(groceryrules_df)
```

