---
title: "Spam SMS classifier with Naive Bays"
author: "Mohammed Zakaria"
#output:
#  html_document:
#    df_print: paged
#    toc: yes
#    keep_md: true
   
  
#  html_notebook:
#    highlight: espresso
#    theme: readable
#    toc: yes
output: github_document

---



Required packages
```{r}
#install.packages("class") # for kNN classification
#library(class)
#install.packages("gmodels") # for CrossTable function at the evaluation
library(gmodels)
#install.packages("caret") # for model tuning
library(caret)
#install.packages("e1071") # to help with model tuning
library(e1071)
#install.packages("pROC") # to make ROC plots
library(pROC)	
#install.packages("tm") # to handle text data
library(tm)
```


Pulling the data: The cancer data is from Brett Lantz's "Machine Learning with R"
a repo for the data is under this link:
https://github.com/mzakariaCERN/Machine-Learning-with-R-datasets/blob/master/wisc_bc_data.csv
and original data can be found under
https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/
```{r}
sms_raw <- read.csv(file="C:/Users/mkzak/Documents/GitHub/FunWithR/FunWithR/2_NB/Data/sms_spam.csv", stringsAsFactors = FALSE)


dim(sms_raw)
str(sms_raw)
summary(sms_raw)

```

We see there are two features. And the feature type has a categorical variables. So we need to convert it to factor


```{r}
sms_raw$type <- as.factor(sms_raw$type)

str(sms_raw$type)
table(sms_raw$type)
```

After installing (loading) tm library, we need to create a container for all the text we are dealing with. This is called a corpus. WE will use 
VCorpus (for volatile corpus: corpus stored in memove, compare it to PCorpus, which is stored on disk).


```{r}
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
typeof(sms_corpus)
```


corpus can read from pdf of MS word using readerControl parameter. Check it out! Notice also that corpus is a list objects. So we can manipulate it as such. 

```{r}
print(sms_corpus)
inspect(sms_corpus[1:3])
```


To see one message, we need to grab that element in from the list, and conver it to characters
```{r}
as.character(sms_corpus[[1]])

```

This can be generalized using lapply

```{r}
lapply(sms_corpus[1:2], as.character)
```


Next, we need to clean the text from special characters, capital letters etc, and convert it into separate words. 

First, convert to lower case

```{r}
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))
```

remember the first message starts with an upper case letter. Let us take a look now

```{r}
as.character(sms_corpus_clean[[1]])
```

next thing, is to remove numbers from SMS. Though some might be useful for the sender/receiver. It doesn't play much value in spam/ham classification.

```{r}
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers) # no need for content_tranformer b/c removeNumbers is built in tm. to see other
# built in functions type getTransformations()
```


Next we remove filler (stop) words suc as: 'and', 'or', and 'but'


Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
